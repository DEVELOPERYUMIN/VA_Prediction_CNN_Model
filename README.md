
![Python](https://img.shields.io/badge/Python-3.9-blue?style=for-the-badge)
![TensorFlow](https://img.shields.io/badge/TensorFlow-DeepLearning-orange?style=for-the-badge)
![Medical AI](https://img.shields.io/badge/Domain-Medical_AI-green?style=for-the-badge)
![CNN](https://img.shields.io/badge/CNN-Baseline-0A66C2?style=for-the-badge)
![VGG](https://img.shields.io/badge/VGG-DeepCNN-555555?style=for-the-badge)
![EfficientNet](https://img.shields.io/badge/EfficientNet-Scaled-00A86B?style=for-the-badge)
![Xception](https://img.shields.io/badge/Xception-Final_Model-D72638?style=for-the-badge)
![ViT](https://img.shields.io/badge/ViT-Transformer-6A0DAD?style=for-the-badge)


---

# ğŸ‘ Visual Acuity Prediction from Fundus Images


> 2024.04 â€“ 2025.09 | CS Lab â€“ ì•ˆì € ì´ë¯¸ì§€ ê¸°ë°˜ ì‹œë ¥ ì˜ˆì¸¡ ê°œì¸ ì—°êµ¬ (ì§€ë„êµìˆ˜ ì§€ë„ í•˜ ìˆ˜í–‰, ì˜ê³¼ëŒ€í•™ ì„ìƒ ë°ì´í„° í˜‘ë ¥)
  

## ğŸ§  Abstract

ë³¸ ì—°êµ¬ëŠ” ë™ì¼ ì£¼ì œë¡œ ì„ í–‰ ë“±ë¡ë˜ì—ˆë˜ ì—°êµ¬( https://www.mdpi.com/2076-3417/12/6/3190 )ì—ì„œ ë™ì¼ í™˜ìì˜ IDê°€ í•™ìŠµ(Train) ë°ì´í„°ì™€ í‰ê°€(Test) ë°ì´í„°ì— ë™ì‹œì— í¬í•¨ë˜ì–´ ìˆìŒì„ í™•ì¸í•œ ê²ƒì—ì„œ ì¶œë°œí•˜ì˜€ë‹¤. ì´ëŸ¬í•œ í™˜ì ë‹¨ìœ„ ë¶„ë¦¬ ë¯¸í¡ì€ ëª¨ë¸ ì„±ëŠ¥ì„ ê³¼ëŒ€í‰ê°€í•  ìˆ˜ ìˆëŠ” ë°ì´í„° ëˆ„ìˆ˜(Data Leakage) ë¬¸ì œë¥¼ ì•¼ê¸°í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ë³¸ ì—°êµ¬ì—ì„œëŠ” í™˜ì ë‹¨ìœ„ ë¶„ë¦¬ë¥¼ ì—„ê²©íˆ ì ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ ì¬êµ¬ì„±í•˜ê³  ëª¨ë¸ì„ ì¬í•™ìŠµí•˜ì˜€ë‹¤.

ë‹¨ìˆœ ì„±ëŠ¥ ê°œì„ ì´ ì•„ë‹Œ, ì˜ë£Œ AIì—ì„œ í•„ìˆ˜ì ì¸ **ë°ì´í„° ì¬ì„¤ê³„(Data Re-engineering)**ë¥¼ ìˆ˜í–‰í•˜ê³ , í´ë˜ìŠ¤ ê°„ íŠ¹ì§• ëª¨í˜¸ì„±(inter-class feature ambiguity)ì„ ì™„í™”í•˜ê¸° ìœ„í•´ **Hierarchical Classification êµ¬ì¡°**ë¥¼ ì œì•ˆí•˜ì˜€ë‹¤.

> Hierarchical classification mitigates inter-class feature ambiguity in visual acuity prediction.

---

# ğŸ” 1. Research Motivation

ê¸°ì¡´ ì‹œë ¥ ì˜ˆì¸¡ ì—°êµ¬ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ì  ë¬¸ì œë¥¼ í™•ì¸í•˜ì˜€ë‹¤:

* ë™ì¼ í™˜ì ì´ë¯¸ì§€ê°€ train/validation/testì— ë™ì‹œì— í¬í•¨
* ì‹¬ê°í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜•
* í´ë˜ìŠ¤ ê°„ íŠ¹ì§• ì°¨ì´ì— ëŒ€í•œ ë¶„ì„ ë¶€ì¡±

ì´ëŠ” ì‹¤ì œ ì„ìƒ í™˜ê²½ì—ì„œ ëª¨ë¸ì´ ì¼ë°˜í™”ë˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì„ ì˜ë¯¸í•œë‹¤.

ë”°ë¼ì„œ ë³¸ ì—°êµ¬ì˜ ëª©í‘œëŠ”:

> ë°ì´í„° êµ¬ì¡°ë¥¼ ì¬ì„¤ê³„í•˜ì—¬ ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ë£Œ AI ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒ

---

# ğŸ—‚ 2. Data Re-Engineering

## 2.1 Patient-wise Split

* í™˜ì ê³ ìœ  ID ê¸°ë°˜ ë°ì´í„° ë¶„ë¦¬
* Train / Validation / Test ê°„ ì¤‘ë³µ ì œê±°
* ë™ì¼ í™˜ì ë°ì´í„°ê°€ ì„œë¡œ ë‹¤ë¥¸ ì„¸íŠ¸ì— í¬í•¨ë˜ì§€ ì•Šë„ë¡ ì„¤ê³„

âœ” Data Leakage ì™„ì „ ì°¨ë‹¨
âœ” ì‹¤ì œ ì„ìƒ í™˜ê²½ê³¼ ìœ ì‚¬í•œ ì¼ë°˜í™” ê²€ì¦

---

## 2.2 Dataset Balancing Strategy

ì˜ë£Œ ë°ì´í„° íŠ¹ì„±ìƒ í´ë˜ìŠ¤ë³„ í™˜ì ìˆ˜ ë° ì´ë¯¸ì§€ ìˆ˜ í¸ì°¨ê°€ ì¡´ì¬í•˜ì˜€ë‹¤.
ê° í´ë˜ìŠ¤ë³„ í™˜ì ìˆ˜ì™€ 1ì¸ë‹¹ ì´ë¯¸ì§€ ê°œìˆ˜(ìµœì†Œ/ìµœëŒ€/í‰ê· )ë¥¼ ë¶„ì„í•œ ê²°ê³¼:

* ì¼ë¶€ í™˜ìëŠ” 100ì¥ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ ë³´ìœ 
* ì¼ë¶€ í™˜ìëŠ” 1ì¥ì˜ ì´ë¯¸ì§€ë§Œ ë³´ìœ 
* í´ë˜ìŠ¤ë³„ í™˜ì ìˆ˜ ì—­ì‹œ ë¶ˆê· í˜• ì¡´ì¬

ì´ë¡œ ì¸í•´ ëª¨ë¸ì´ íŠ¹ì • í™˜ìì˜ íŠ¹ì„±ì„ ê³¼ë„í•˜ê²Œ í•™ìŠµí•  ìœ„í—˜ì´ ìˆì—ˆë‹¤.

### âœ” Generalization ê°œì„  ì „ëµ

* í•œ í™˜ìë‹¹ **ìµœëŒ€ 10ì¥ì˜ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©**
* ìµœëŒ€í•œ ë‹¤ì–‘í•œ í™˜ì ë°ì´í„°ë¥¼ í¬í•¨í•˜ë„ë¡ ì„¤ê³„
* ê³¼ë‹¤ ìƒ˜í”Œ í™˜ìì— ëŒ€í•œ ê³¼ì í•© ë°©ì§€
* ëª¨ë¸ì´ â€œí™˜ì íŠ¹ì§•â€ì´ ì•„ë‹Œ â€œì§ˆë³‘ íŠ¹ì§•â€ì„ í•™ìŠµí•˜ë„ë¡ ìœ ë„

ì´ë¥¼ í†µí•´:

> ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ êµ¬ì¡°ì ìœ¼ë¡œ ê°œì„ 

---

## 2.3 Class Mapping

ì›ë³¸ 11-class ë°ì´í„°ë¥¼ 4-class êµ¬ì¡°ë¡œ ì¬ì„¤ê³„:

```
0 â†’ Class 0
1,2 â†’ Class 1
3,4,5,6,7 â†’ Class 2
8,9,10 â†’ Class 3
```

ëª©ì :

* ê·¹ë‹¨ê°’ ì™„í™”
* ë¶„í¬ ì•ˆì •í™”
* ê³„ì¸µì  ë¶„ë¥˜ êµ¬ì¡° ì„¤ê³„

---

## 2.4 Balanced Sampling

* ë‹¨ê³„ë³„ ë¶„ë¥˜ë§ˆë‹¤ ë³„ë„ ìƒ˜í”Œë§ ì „ëµ ì ìš©
* íŠ¹ì • í´ë˜ìŠ¤ í¸í–¥ ìµœì†Œí™”
* í•™ìŠµ ë°ì´í„° ë¶„í¬ ì•ˆì •í™”

---

# ğŸ” 3. Model Selection Strategy

ì „ì²´ 4-class ì‹¤í—˜ ì´ì „ì—,
**í´ë˜ìŠ¤ ê°„ ì°¨ì´ê°€ ë¹„êµì  ëšœë ·í•˜ë©´ì„œ ë°ì´í„° ìˆ˜ê°€ ìœ ì‚¬í•œ 0ê³¼ 5 í´ë˜ìŠ¤ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì‚¬ì „ ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ì˜€ë‹¤.**

### ğŸ“Œ ëª©ì 

* ëª¨ë¸ feature extraction ëŠ¥ë ¥ ë¹„êµ
* ë°ì´í„° ìˆ˜ í¸í–¥ ì—†ëŠ” ê³µì •í•œ í‰ê°€
* Backbone ì„ íƒ ê¸°ì¤€ ë§ˆë ¨

---

## ğŸ“Š ëª¨ë¸ ë¹„êµ ê²°ê³¼

| Metric    | ViT    | VGG19  | VGG16  | Xception   |
| --------- | ------ | ------ | ------ | ---------- |
| Precision | 0.7183 | 0.7543 | 0.7872 | **0.8379** |
| Recall    | 0.7050 | 0.8391 | 0.8169 | **0.9065** |
| F1 Score  | 0.7116 | 0.7946 | 0.8018 | **0.8709** |
| AUC       | 0.80   | 0.86   | 0.87   | **0.92**   |

### âœ… ìµœì¢… ì„ íƒ ëª¨ë¸: **Xception**

ì„ íƒ ê·¼ê±°:

* ê°€ì¥ ë†’ì€ F1 Score
* ê°€ì¥ ë†’ì€ AUC
* ë†’ì€ Recall (ì˜ë£Œ AIì—ì„œ FN ìµœì†Œí™” ì¤‘ìš”)

---

# ğŸ§  4. Model Architecture & Training Setup

## Backbone

* Fine-tuned **Xception**
* Input size: **299 Ã— 299**

---

## âš™ Training Parameters

* Optimizer: **Adam**
* Learning rate: **1e-4**
* Batch size: **64**
* Epoch: **25 (Early Stopping ì ìš©)**
* Train : Validation : Test = **0.8 : 0.1 : 0.1**
* Mixed Precision Training ì‚¬ìš©

---

## ğŸ¯ Training Strategy

* Early Stopping â†’ ê³¼ì í•© ë°©ì§€
* Mixed Precision â†’ ì—°ì‚° íš¨ìœ¨ ê°œì„ 
* Patient-wise Split â†’ ì¼ë°˜í™” ê²€ì¦
* Per-patient Image Cap (max 10) â†’ í™˜ì í¸í–¥ ìµœì†Œí™”


---

# ğŸ” 5. Hierarchical Classification Framework

```
Fundus Image
      â†“
Fine-tuned Xception
      â†“
Level 1: (Class 0,1) vs (Class 2,3)
      â†“
Level 2A: Class 0 vs Class 1
Level 2B: Class 2 vs Class 3
      â†“
Final 4-Class Prediction
```

---

# ğŸ¯ 6. Why Hierarchical Classification?

Flat 4-class classificationì€ ìœ ì‚¬ í´ë˜ìŠ¤ ê°„ íŠ¹ì§• í˜¼ë™ì„ ìœ ë°œí•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.

Hierarchical êµ¬ì¡°ëŠ”:

* í° íŠ¹ì§• ì°¨ì´ë¶€í„° ìš°ì„  ë¶„ë¦¬
* ì ì§„ì  decision boundary í˜•ì„±
* inter-class ambiguity ì™„í™”
* ë³´ë‹¤ ì•ˆì •ì ì¸ discriminative boundary í˜•ì„±

---

# ğŸ“ˆ 7. Experimental Validation

ê° ë‹¨ê³„ì—ì„œ:

* Precision
* Recall
* F1 Score
* Confusion Matrix
* ROC Curve

ë¥¼ í†µí•´ ì„±ëŠ¥ ê²€ì¦ ìˆ˜í–‰.

---

## ğŸ“Š Performance

<img width="990" height="471" alt="image" src="https://github.com/user-attachments/assets/a068f3e6-2e71-47f2-b5ef-68f535b36036" />



<br><br>




### Level 1 Confusion Mat & ROC Curve
 <img width="1556" height="614" alt="image" src="https://github.com/user-attachments/assets/10cf4778-c3f5-436c-af3a-4dccc992bdee" />

<br><br>

### Level 2A Confusion Mat & ROC Curve
 <img width="1642" height="692" alt="image" src="https://github.com/user-attachments/assets/a164951a-3756-41d3-b981-8a7d789a69b3" />

<br><br>

### Level 2B Confusion Mat & ROC Curve
 <img width="1642" height="622" alt="image" src="https://github.com/user-attachments/assets/31e9259d-5aa4-4375-b1a9-8f616f7ce15b" />
<br><br>

---

# ğŸ§ª 8. Training Strategy

* Early Stopping â†’ ê³¼ì í•© ë°©ì§€
* Mixed Precision â†’ ì—°ì‚° íš¨ìœ¨ ê°œì„ 
* Balanced Sampling â†’ í¸í–¥ ê°ì†Œ
* Patient-wise Split â†’ ì¼ë°˜í™” ê²€ì¦

---

# âš ï¸ ë°ì´í„° ì‚¬ìš© ë° ê³µê°œ ì œí•œ ì•ˆë‚´

ë³¸ ì—°êµ¬ëŠ” ëª¨ ëŒ€í•™ë³‘ì›ìœ¼ë¡œë¶€í„° ì—°êµ¬ ëª©ì  í•˜ì— ì œê³µë°›ì€ ì„ìƒ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.

ì˜ë£Œ ë°ì´í„° ë³´í˜¸ ì •ì±…ì— ë”°ë¼:

* ì›ë³¸ ë°ì´í„°ëŠ” ê³µê°œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
* ì „ì²˜ë¦¬ ë°ì´í„°ëŠ” ê³µê°œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
* í•™ìŠµëœ ëª¨ë¸ weight íŒŒì¼ì€ ê³µê°œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ë³¸ ì €ì¥ì†ŒëŠ” ì—°êµ¬ ë°©ë²•ë¡ , ëª¨ë¸ êµ¬ì¡° ë° ì„±ëŠ¥ ê²°ê³¼ ê³µìœ  ëª©ì ì…ë‹ˆë‹¤.

---

# ğŸ”® Future Work

* Regression ê¸°ë°˜ ì‹œë ¥ ìˆ˜ì¹˜ ì˜ˆì¸¡ í™•ì¥
* Multimodal í•™ìŠµ (ì˜ìƒ + ì„ìƒ ì •ë³´)
* Explainable AI (Grad-CAM)
* 11-class ì„¸ë¶€ ë¶„ë¥˜ ë³µì› ì‹¤í—˜

---

# ğŸ íŠ¸ëŸ¬ë¸” ìŠˆíŒ… (ë‚˜ì¦ì—)

- 01//23 ë¶„ë¥˜ ì–´ë ¤ì› ë˜ê±° -> í´ë˜ìŠ¤ë³„ íŠ¹ì§• íŒŒì•… í›„ ì•ˆì € í¬ë¡­í•´ì„œ ë°ì´í„° ì¶”ê°€í•œ ê±° ë„£ì–´ë¼
- vgg ëª¨ë¸ ê³¼ì í•©(íŒŒë¼ë¯¸í„° ë§ì•„ì„œ ) -> xception + early stopping
- í™˜ì ë°ì´í„° ë¶ˆê· í˜•
- íŠ¸ë ˆì¸ ë†’ ë°¸ë¦¬ ë‚® ì˜¤ë²„í”¼íŒ… ->ìƒˆë¡œìš´ í™˜ìê°€ ì•„ë‹ˆë¼ ì´ë¯¸ ë³¸ í™˜ì -> ê²€ì¦ ë‹¨ê³„ ë” ì¶”ê°€í•¨ 
  



---

